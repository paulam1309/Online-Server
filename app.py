# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10m7g8FFbB9-EHKAqBO75tViYmgDGnoaO

# **FastAPI (Servicio de Inferencia)**

Es el endpoint encargado de recibir ventanas, armar el dataframe con el orden de schema-json, llama al pipeline de SVM + Calibrador y devuelve predict_label + confianza.

LLama a su vez a policy engine en caso de que la confianza baje del 70%

**LIBRERÍAS**
"""



import os, json, joblib
import pandas as pd
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from starlette.middleware.cors import CORSMiddleware
import policy  # importa el motor de reglas
import psycopg2
from psycopg2 import errors
from psycopg2.extras import RealDictCursor
from datetime import datetime, timezone
from typing import Optional, Dict, Any

#SL
import dill
from river import tree, ensemble, metrics

"""**CONEXIÓN CON CON LA BASE DE DATOS**"""

DATABASE_URL = os.environ["DATABASE_URL"]
def get_conn():
    return psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)

"""**Función de tiempos**"""

def _to_utc(dt):
    # si viene sin tz, asúmelo en UTC
    return dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)

"""**CARGA DE ARCHIVOS NECESARIOS**"""

MODEL_PATH = os.getenv("MODEL_PATH", "models/svm_calibrado.pkl")
SCHEMA_PATH = os.getenv("SCHEMA_PATH", "processing/schema.json")

try:
    MODEL = joblib.load(MODEL_PATH)  # pipeline: scaler → SVM → calibración
except Exception as e:
    raise RuntimeError(f"No pude cargar el modelo en {MODEL_PATH}: {e}")

try:
    with open(SCHEMA_PATH, "r", encoding="utf-8") as f:
        SCHEMA = json.load(f)
    FEATURES = SCHEMA["features"]
    CLASSES = getattr(MODEL, "classes_", SCHEMA.get("classes", []))
except Exception as e:
    raise RuntimeError(f"No pude cargar el schema en {SCHEMA_PATH}: {e}")

"""**Configuraciones para conexión remota**"""

app = FastAPI(title="HAR Online – Inference")

# CORS para que la app de Flutter pueda llamar al API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

"""**Helpers**"""

# --- helpers ---
def _df_from_window_row(row: Dict[str, Any]) -> pd.DataFrame:
    if row.get("features"):
        feats: Dict[str, Any] = row["features"]
        data = {f: feats.get(f, 0.0) for f in FEATURES}
    else:
        data = {f: row.get(f, 0.0) for f in FEATURES}
    return pd.DataFrame([data], columns=FEATURES)

def _center_ts(row: Dict[str, Any]) -> float:
    st, et = row["start_time"], row["end_time"]
    c = st + (et - st) / 2
    if c.tzinfo is None:
        c = c.replace(tzinfo=timezone.utc)
    return c.timestamp()

def _svm_predict_row(row: Dict[str, Any]) -> tuple[str, float]:
    """Predicción con el SVM calibrado (idéntico a /predict_by_window)."""
    X = _df_from_window_row(row)
    proba = MODEL.predict_proba(X)[0]
    i_top = int(proba.argmax())
    pred_label = str(CLASSES[i_top])
    confianza = float(proba[i_top])
    return pred_label, confianza

def _update_window_preds(cur, win_id: int, pred_label: str, confianza: float) -> None:
    cur.execute(
        """
        UPDATE windows
           SET pred_label = %s,
               confianza  = %s
         WHERE id = %s
        """,
        (pred_label, confianza, win_id),
    )

"""**Models**"""

class PredictByWindowReq(BaseModel):
    id: int = Field(..., description="PK de windows")

class LabelReq(BaseModel):
    id_usuario: int
    session_id: int
    start_ts: datetime
    end_ts: datetime
    label: str
    reason: Optional[str] = None
    pending_id: int | None = None

class MarkReq(BaseModel):
    id_usuario: int
    session_id: int
    when: Optional[datetime] = None

class SLPredictReq(BaseModel):
    id: int
    actividad: str
    precision: Optional[float] = None

class PredictPendingReq(BaseModel):
    limit: int = 200
    id_usuario: Optional[int] = None
    session_id: Optional[int] = None

"""**Gets**


Realiza un monitoreo para corroborar que el servidor esté en producción y haya cargado los archivos.
"""

@app.get("/health")
def health():
    return {"ok": True, "model": os.path.basename(MODEL_PATH), "n_features": len(FEATURES)}

@app.get("/schema")
def schema():
    return {"features": FEATURES, "classes": list(map(str, CLASSES))}

"""**Endpoint de Ingest**


Se construye del Dataframe y se pasa al .pkl para obtener pred_label + confianza
"""

@app.post("/predict_by_window")
def predict_by_window(req: PredictByWindowReq):
    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # 1) Leer ventana
        cur.execute("SELECT * FROM windows WHERE id = %s", (req.id,))
        w = cur.fetchone()
        if not w:
            raise HTTPException(404, f"id {req.id} no existe")

        # 2) Predicción SVM calibrado
        pred_label, confianza = _svm_predict_row(w)

        uid = int(w["id_usuario"])
        sid = int(w["session_id"])
        center_ts = _center_ts(w)

        cur.execute("""
            SELECT created_at, label
              FROM intervalos_label
             WHERE session_id = %s
               AND label IS NOT NULL
             ORDER BY created_at ASC
             LIMIT 1
        """, (sid,))
        seed = cur.fetchone()
        if seed:
            policy.mark_labeled(
                uid, sid,
                now_ts=seed["created_at"].timestamp(),
                label=seed["label"]
            )

        # 3) Motor de políticas
        ask, ask_reason = policy.should_ask(
            uid, sid, confianza, pred_label=pred_label, now_ts=center_ts
        )

        # 4) Persistir predicción en windows (misma transacción)
        cur.execute(
            "UPDATE windows SET pred_label=%s, confianza=%s WHERE id=%s",
            (pred_label, confianza, req.id),
        )

        ask_id = None

        # 5) Si hay que preguntar: marcar y luego UPDATE-then-INSERT
        if ask:
            policy.mark_asked(uid, sid, center_ts, ask_reason)

            st = w["start_time"]; et = w["end_time"]
            if st.tzinfo is None: st = st.replace(tzinfo=timezone.utc)
            else:                 st = st.astimezone(timezone.utc)
            if et.tzinfo is None: et = et.replace(tzinfo=timezone.utc)
            else:                 et = et.astimezone(timezone.utc)

            # 5.1) Intento de UPDATE a la fila pendiente de esa sesión (label IS NULL)
            cur.execute("""
                UPDATE intervalos_label
                  SET reason=%s,
                      start_ts=%s,
                      end_ts=%s,
                      created_at=NOW()
                WHERE id_usuario=%s
                  AND session_id=%s
                  AND label IS NULL
                RETURNING id
            """, (ask_reason, st, et, uid, sid))
            row_upd = cur.fetchone()

            if row_upd:
                ask_id = row_upd["id"]
            else:
                # 5.2) Si no existía pendiente, INSERT nueva pendiente (label NULL)
                cur.execute("""
                    INSERT INTO intervalos_label
                        (id_usuario, session_id, start_ts, end_ts, label, reason, created_at)
                    VALUES (%s, %s, %s, %s, NULL, %s, NOW())
                    RETURNING id
                """, (uid, sid, st, et, ask_reason))
                ask_id = cur.fetchone()["id"]

        # SL (sombra): predecir y guardar en windows
        sl_pred, sl_conf = _sl_predict_row(w)
        if sl_pred is not None:
            cur.execute(
                "UPDATE windows SET actividad=%s, precision=%s WHERE id=%s",
                (sl_pred, sl_conf, req.id)
            )

        # ¿Qué devuelves? Si promoviste, responde con SL; si no, SVM.
        resp_pred = sl_pred if SL_PROMOTED and sl_pred is not None else pred_label
        resp_conf = sl_conf if SL_PROMOTED and sl_conf is not None else confianza

        # 6) Commit al salir del with si no hubo excepción
    return {
        "id": req.id,
        "pred_label": resp_pred,
        "confianza": resp_conf,
        "actividad": sl_pred,         # SL
        "precision": sl_conf,         # SL
        "ask_label": ask,
        "ask_reason": ask_reason,
        "ask_id": ask_id,
        "classes": list(map(str, CLASSES)),
        "sl_shadow": {"pred": sl_pred, "conf": sl_conf, "promoted": SL_PROMOTED}
    }

"""**Endpoint de prediccion pendiente**"""

@app.post("/predict_pending")
def predict_pending(req: PredictPendingReq):
    """
    Procesa ventanas donde pred_label es NULL.
    Puedes filtrar por id_usuario y/o session_id para un barrido específico.
    """
    done = 0

    # Construimos WHERE dinámico
    where = ["pred_label IS NULL"]
    params: list[Any] = []
    if req.id_usuario is not None:
        where.append("id_usuario = %s")
        params.append(req.id_usuario)
    if req.session_id is not None:
        where.append("session_id = %s")
        params.append(req.session_id)
    where_sql = " AND ".join(where)

    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Tomamos un lote estable y lo bloqueamos para evitar colisiones
        sql_sel = f"""
            SELECT *
              FROM windows
             WHERE {where_sql}
             ORDER BY id ASC
             LIMIT %s
             FOR UPDATE SKIP LOCKED
        """
        cur.execute(sql_sel, (*params, req.limit))
        rows = cur.fetchall()

        for row in rows:
            win_id = int(row["id"])
            # si no hay features JSON, _df_from_window_row usará columnas sueltas
            try:
                pred, conf = _svm_predict_row(row)
                _update_window_preds(cur, win_id, pred, conf)
                done += 1
            except Exception as e:
                # si una fila rara rompe, saltamos y seguimos con las demás
                # (opcional: loggear e)
                continue

        conn.commit()

    return {"processed": done}

"""**Endpoint para registrar que el usuario respondió una etiqueta**"""

@app.post("/label")
def post_label(req: LabelReq):
    st = req.start_ts.astimezone(timezone.utc)
    et = req.end_ts.astimezone(timezone.utc)
    if et <= st:
        raise HTTPException(400, "end_ts debe ser > start_ts")

    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # 1) Cerrar/crear intervalo (si hay pendiente, actualízalo; si no, inserta)
        cur.execute("""
            SELECT id
              FROM intervalos_label
             WHERE id_usuario = %s
               AND session_id  = %s
               AND label IS NULL
             ORDER BY created_at DESC
             LIMIT 1
             FOR UPDATE
        """, (req.id_usuario, req.session_id))
        pend = cur.fetchone()

        if pend:
            cur.execute("""
                UPDATE intervalos_label
                   SET label=%s, reason=%s, start_ts=%s, end_ts=%s, created_at=NOW()
                 WHERE id=%s
                RETURNING id
            """, (req.label, req.reason, st, et, pend["id"]))
            interval_id = cur.fetchone()["id"]
        else:
            cur.execute("""
                INSERT INTO intervalos_label
                    (start_ts, end_ts, label, reason, created_at, id_usuario, session_id)
                VALUES (%s, %s, %s, %s, NOW(), %s, %s)
                RETURNING id
            """, (st, et, req.label, req.reason, req.id_usuario, req.session_id))
            interval_id = cur.fetchone()["id"]
        # 2) Commit en la misma transacción
        conn.commit()

    policy.mark_labeled(req.id_usuario, req.session_id, et.timestamp(), req.label)
    return {"ok": True, "interval_id": interval_id}

@app.post("/policy/asked")
def policy_mark_asked(req: MarkReq):
    policy.mark_asked(req.id_usuario, req.session_id, req.when.timestamp() if req.when else None)
    return {"ok": True}

@app.post("/policy/labeled")
def policy_mark_labeled(req: MarkReq):
    policy.mark_labeled(req.id_usuario, req.session_id, req.when.timestamp() if req.when else None)
    return {"ok": True}

"""**STREAM LEARNING**

Cargar o crear el learner
"""

@app.on_event("startup")
def _startup():
    import river
    print("River version:", getattr(river, "__version__", "unknown"),
          "SL_ALGO env:", SL_ALGO)
    _sl_load_latest(conn)

"""**Configuración de SL**"""

SL_ALGO = "arf"  # "arf" (AdaptiveRandomForest) o "ht" (HoeffdingTree)
SL_LEARNER = None
SL_METRIC = metrics.Accuracy()
SL_PROMOTED = False  # cuando pase a principal
SL_SAVE_EVERY = 200  # guarda modelo cada N updates
PROMOTE_ACC = 0.85
PROMOTE_MIN_UPDATES = 2000

def _sl_make_learner():
    """Construye el learner de SL según SL_ALGO, con fallback seguro a HT."""
    from river import tree

    algo = (SL_ALGO or "HT").upper()

    if algo == "ARF":
        try:
            try:
                # River >= ~0.20
                from river.ensemble import ARFClassifier
            except Exception:
                # Intento con nombre antiguo (algunas builds)
                from river.ensemble import AdaptiveRandomForestClassifier as ARFClassifier
            return ARFClassifier(
                n_models=10,
                max_features="sqrt",
                lambda_value=6,
            )
        except Exception as e:
            # <<< NO reventar el startup >>>
            print("WARN: ARF no disponible en esta build de river → usando HT. Detalle:", repr(e))

    # Default / fallback: Hoeffding Tree
    return tree.HoeffdingTreeClassifier(
        grace_period=50,
        delta=1e-5,
        leaf_prediction="mc",
    )

"""**Helpers para features**"""

def _row_to_x(row: dict) -> dict:
    # Usa EXACTAMENTE las mismas features que usas para el SVM
    # row viene de SELECT * FROM windows
    x = {}
    for f in FEATURES:
        # OJO: si tus features están en columnas directas (no JSON), castea:
        # x[f] = float(row[f])
        # Si algunas están en un JSON (ej. "features"), adáptalo:
        if f in row:
            x[f] = float(row[f]) if row[f] is not None else 0.0
        elif "features" in row and isinstance(row["features"], dict) and f in row["features"]:
            x[f] = float(row["features"][f]) if row["features"][f] is not None else 0.0
        else:
            x[f] = 0.0
    return x

"""**Funciones para Postgres**"""

def _sl_save(conn):
    global SL_LEARNER, SL_METRIC, SL_ALGO, SL_PROMOTED
    blob = dill.dumps(SL_LEARNER)
    metric_json = {"accuracy": SL_METRIC.get()}  # métrica prequential
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO sl_models (algo, promoted, n_updates, metric, blob)
            VALUES (%s, %s, %s, %s, %s)
        """, (SL_ALGO, SL_PROMOTED, getattr(SL_LEARNER, "_n_updates", 0), json.dumps(metric_json), psycopg2.Binary(blob)))
    conn.commit()

def _sl_load_latest(conn):
    global SL_LEARNER, SL_METRIC, SL_PROMOTED, SL_ALGO
    with conn.cursor(cursor_factory=RealDictCursor) as cur:
        cur.execute("""
            SELECT * FROM sl_models
            ORDER BY id DESC
            LIMIT 1
        """)
        row = cur.fetchone()
        if row:
            SL_ALGO = row["algo"]
            SL_PROMOTED = bool(row["promoted"])
            SL_LEARNER = dill.loads(bytes(row["blob"]))
            SL_METRIC = metrics.Accuracy()
        else:
            SL_LEARNER = _sl_make_learner()
            SL_METRIC = metrics.Accuracy()
            SL_PROMOTED = False

"""**Inferir con SL**"""

def _sl_predict_row(row: dict):
    if SL_LEARNER is None:
        return None, None
    x = _row_to_x(row)
    proba = SL_LEARNER.predict_proba_one(x)  # dict {clase: prob}
    if not proba:
        return None, None
    cls = max(proba, key=proba.get)
    conf = float(proba[cls])
    return str(cls), conf

"""**Entrenar SL con etiquetas del usuario**"""

def _sl_train_on_row(row: dict, label: str):
    """
    Prequential: primero evalúa, luego entrena.
    Actualiza SL_METRIC. Marca sl_trained=true en windows.
    """
    global SL_LEARNER, SL_METRIC
    x = _row_to_x(row)
    y_true = str(label)
    y_hat = SL_LEARNER.predict_one(x)
    if y_hat is not None:
        SL_METRIC.update(y_true, y_hat)
    SL_LEARNER.learn_one(x, y_true)
    # contador interno (para decidir cuándo guardar)
    n_updates = getattr(SL_LEARNER, "_n_updates", 0) + 1
    setattr(SL_LEARNER, "_n_updates", n_updates)
    return n_updates

"""**Endpoint para entrenar**"""

class SLTrainReq(BaseModel):
    limit: int = 500  # cuántas ventanas entrenar por llamada

@app.post("/sl_train_pending")
def sl_train_pending(req: SLTrainReq):
    global SL_PROMOTED
    """
    Busca ventanas con etiqueta (etiqueta no nula) y sl_trained=false,
    entrena el SL y marca sl_trained=true.
    """
    done = 0
    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # trae pendientes
        cur.execute("""
            SELECT id, *
              FROM windows
             WHERE etiqueta IS NOT NULL
               AND sl_trained = FALSE
             ORDER BY id
             LIMIT %s
        """, (req.limit,))
        rows = cur.fetchall()
        if not rows:
            return {"trained": 0, "metric": {"accuracy": SL_METRIC.get()}}

        for r in rows:
            n_updates = _sl_train_on_row(r, r["etiqueta"])
            # marca como entrenada
            cur.execute("UPDATE windows SET sl_trained=TRUE WHERE id=%s", (r["id"],))
            done += 1

        # persiste modelo cada SL_SAVE_EVERY
        if n_updates % SL_SAVE_EVERY == 0:
            _sl_save(conn)

        # Para promover SL
        if SL_METRIC.get() >= PROMOTE_ACC and getattr(SL_LEARNER, "_n_updates", 0) >= PROMOTE_MIN_UPDATES:
            SL_PROMOTED = True
            _sl_save(conn)
        conn.commit()

    return {
        "trained": done,
        "metric": {"accuracy": SL_METRIC.get()},
        "n_updates": getattr(SL_LEARNER, "_n_updates", 0)
    }

"""**Endpoint de estado y promoción**"""

@app.get("/sl_status")
def sl_status():
    return {
        "algo": SL_ALGO,
        "promoted": SL_PROMOTED,
        "metric": {"accuracy": SL_METRIC.get()},
        "n_updates": getattr(SL_LEARNER, "_n_updates", 0)
    }

@app.post("/sl_promote")
def sl_promote():
    global SL_PROMOTED
    SL_PROMOTED = True
    # opcional: guarda snapshot con promoted=true
    with get_conn() as conn:
        _sl_save(conn)
    return {"ok": True, "promoted": True}

@app.post("/sl_reset")
def sl_reset():
    """Reinicia el learner en sombra (cuidado: borra aprendizaje actual)."""
    global SL_LEARNER, SL_METRIC, SL_PROMOTED
    SL_LEARNER = _sl_make_learner()
    SL_METRIC = metrics.Accuracy()
    SL_PROMOTED = False
    with get_conn() as conn:
        _sl_save(conn)
    return {"ok": True}
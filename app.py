# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10m7g8FFbB9-EHKAqBO75tViYmgDGnoaO

# **FastAPI (Servicio de Inferencia)**

Es el endpoint encargado de recibir ventanas, armar el dataframe con el orden de schema-json, llama al pipeline de SVM + Calibrador y devuelve predict_label + confianza.

LLama a su vez a policy engine en caso de que la confianza baje del 70%

**LIBRERÍAS**
"""



import os, json, joblib
import pandas as pd
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from starlette.middleware.cors import CORSMiddleware
import policy  # importa el motor de reglas
import psycopg2
from psycopg2 import errors
from psycopg2.extras import RealDictCursor
from datetime import datetime, timezone
from typing import Optional, Dict, Any

#SL
import dill
from river import tree, ensemble, metrics
from io import BytesIO

"""**CONEXIÓN CON CON LA BASE DE DATOS**"""

DATABASE_URL = os.environ["DATABASE_URL"]
def get_conn():
    return psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)

"""**Función de tiempos**"""

def _to_utc(dt):
    # si viene sin tz, asúmelo en UTC
    return dt if dt.tzinfo else dt.replace(tzinfo=timezone.utc)

"""**CARGA DE ARCHIVOS NECESARIOS**"""

MODEL_PATH = os.getenv("MODEL_PATH", "models/svm_calibrado.pkl")
SCHEMA_PATH = os.getenv("SCHEMA_PATH", "processing/schema.json")

try:
    MODEL = joblib.load(MODEL_PATH)  # pipeline: scaler → SVM → calibración
except Exception as e:
    raise RuntimeError(f"No pude cargar el modelo en {MODEL_PATH}: {e}")

try:
    with open(SCHEMA_PATH, "r", encoding="utf-8") as f:
        SCHEMA = json.load(f)
    FEATURES = SCHEMA["features"]
    CLASSES = getattr(MODEL, "classes_", SCHEMA.get("classes", []))
except Exception as e:
    raise RuntimeError(f"No pude cargar el schema en {SCHEMA_PATH}: {e}")

"""**Configuraciones para conexión remota**"""

app = FastAPI(title="HAR Online – Inference")

# CORS para que la app de Flutter pueda llamar al API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

"""**Helpers**"""

# --- helpers ---
def _df_from_window_row(row: Dict[str, Any]) -> pd.DataFrame:
    if row.get("features"):
        feats: Dict[str, Any] = row["features"]
        data = {f: feats.get(f, 0.0) for f in FEATURES}
    else:
        data = {f: row.get(f, 0.0) for f in FEATURES}
    return pd.DataFrame([data], columns=FEATURES)

def _center_ts(row: Dict[str, Any]) -> float:
    st, et = row["start_time"], row["end_time"]
    c = st + (et - st) / 2
    if c.tzinfo is None:
        c = c.replace(tzinfo=timezone.utc)
    return c.timestamp()

def _svm_predict_row(row: Dict[str, Any]) -> tuple[str, float]:
    """Predicción con el SVM calibrado (idéntico a /predict_by_window)."""
    X = _df_from_window_row(row)
    proba = MODEL.predict_proba(X)[0]
    i_top = int(proba.argmax())
    pred_label = str(CLASSES[i_top])
    confianza = float(proba[i_top])
    return pred_label, confianza

def _update_window_preds(cur, win_id: int, pred_label: str, confianza: float) -> None:
    cur.execute(
        """
        UPDATE windows
           SET pred_label = %s,
               confianza  = %s
         WHERE id = %s
        """,
        (pred_label, confianza, win_id),
    )

"""**Models**"""

class PredictByWindowReq(BaseModel):
    id: int = Field(..., description="PK de windows")

class LabelReq(BaseModel):
    id_usuario: int
    session_id: int
    start_ts: datetime
    end_ts: datetime
    label: str
    reason: Optional[str] = None
    pending_id: int | None = None

class MarkReq(BaseModel):
    id_usuario: int
    session_id: int
    when: Optional[datetime] = None

class SLPredictReq(BaseModel):
    id: int
    actividad: str
    precision: Optional[float] = None

class PredictPendingReq(BaseModel):
    limit: int = 200
    id_usuario: Optional[int] = None
    session_id: Optional[int] = None

"""**Gets**


Realiza un monitoreo para corroborar que el servidor esté en producción y haya cargado los archivos.
"""

@app.get("/health")
def health():
    return {"ok": True, "model": os.path.basename(MODEL_PATH), "n_features": len(FEATURES)}

@app.get("/schema")
def schema():
    return {"features": FEATURES, "classes": list(map(str, CLASSES))}

"""**Endpoint de Ingest**


Se construye del Dataframe y se pasa al .pkl para obtener pred_label + confianza
"""

@app.post("/predict_by_window")
def predict_by_window(req: PredictByWindowReq):
    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # 1) Leer ventana
        cur.execute("SELECT * FROM windows WHERE id = %s", (req.id,))
        w = cur.fetchone()
        if not w:
            raise HTTPException(404, f"id {req.id} no existe")

        # 2) Predicción SVM calibrado
        pred_label, confianza = _svm_predict_row(w)

        uid = int(w["id_usuario"])
        sid = int(w["session_id"])
        center_ts = _center_ts(w)

        # Semilla de policy: último label confirmado (uid, sid)
        cur.execute("""
            SELECT COALESCE(EXTRACT(EPOCH FROM end_ts), EXTRACT(EPOCH FROM created_at)) AS ts, label
              FROM intervalos_label
             WHERE id_usuario = %s AND session_id = %s AND label IS NOT NULL
             ORDER BY COALESCE(end_ts, created_at) DESC
             LIMIT 1
        """, (uid, sid))
        seed = cur.fetchone()
        if seed:
            policy.mark_labeled(uid, sid, now_ts=float(seed["ts"]), label=seed["label"])

        # 3) SL: entrenamiento oportunista con ventanas etiquetadas pendientes
        trained_now = 0
        if SL_ENABLED and SL_LEARNER is not None:
            cur.execute("""
                SELECT id, features, etiqueta, *
                  FROM windows
                 WHERE id_usuario = %s
                   AND session_id  = %s
                   AND etiqueta IS NOT NULL
                   AND COALESCE(sl_trained, FALSE) = FALSE
                 ORDER BY id ASC
                 LIMIT %s
                 FOR UPDATE SKIP LOCKED
            """, (uid, sid, SL_TRAIN_CHUNK))
            rows_train = cur.fetchall()

            global SL_UPDATES
            for r in rows_train:
                x = _row_to_x(r); y = r["etiqueta"]
                try:
                    y_hat = SL_LEARNER.predict_one(x)
                    if y_hat is not None:
                        # ¡Sin reasignar!
                        SL_METRIC.update(y_true=y, y_pred=y_hat)
                except Exception:
                    pass
                SL_LEARNER.learn_one(x, y)
                SL_UPDATES += 1
                trained_now += 1
                cur.execute("UPDATE windows SET sl_trained = TRUE WHERE id = %s", (r["id"],))

            # Snapshot periódico
            if trained_now and (SL_UPDATES % SL_SNAPSHOT_EVERY == 0):
                _sl_snapshot(conn, promoted=False)

        # 4) Motor de políticas (preguntar etiqueta si baja confianza)
        ask, ask_reason = policy.should_ask(
            uid, sid, confianza, pred_label=pred_label, now_ts=center_ts
        )

        # 5) Guardar predicción SVM
        cur.execute(
            "UPDATE windows SET pred_label=%s, confianza=%s WHERE id=%s",
            (pred_label, confianza, req.id),
        )

        ask_id = None
        if ask:
            policy.mark_asked(uid, sid, center_ts, ask_reason)

            # Normaliza a UTC antes de escribir intervalo pendiente
            st = w["start_time"]; et = w["end_time"]
            if st.tzinfo is None: st = st.replace(tzinfo=timezone.utc)
            else:                 st = st.astimezone(timezone.utc)
            if et.tzinfo is None: et = et.replace(tzinfo=timezone.utc)
            else:                 et = et.astimezone(timezone.utc)

            # UPDATE-then-INSERT de la pendiente
            cur.execute("""
                UPDATE intervalos_label
                   SET reason = %s,
                       start_ts = %s,
                       end_ts   = %s,
                       created_at = NOW()
                 WHERE id_usuario = %s
                   AND session_id  = %s
                   AND label IS NULL
                 RETURNING id
            """, (ask_reason, st, et, uid, sid))
            row_upd = cur.fetchone()

            if row_upd:
                ask_id = row_upd["id"]
            else:
                cur.execute("""
                    INSERT INTO intervalos_label
                        (id_usuario, session_id, start_ts, end_ts, label, reason, created_at)
                    VALUES (%s, %s, %s, %s, NULL, %s, NOW())
                    RETURNING id
                """, (uid, sid, st, et, ask_reason))
                ask_id = cur.fetchone()["id"]

        # 6) SL en sombra: escribir actividad/precision si ya calentó
        sl_pred, sl_conf = None, None
        if SL_ENABLED and SL_LEARNER is not None and SL_UPDATES >= SL_MIN_SHADOW_UPDATES:
            x = _row_to_x(w)
            try:
                sl_pred = SL_LEARNER.predict_one(x)
                proba   = SL_LEARNER.predict_proba_one(x) or {}
                sl_conf = float(proba.get(sl_pred, 0.0)) if sl_pred is not None else None
            except Exception:
                sl_pred, sl_conf = None, None

            cur.execute("""
                UPDATE windows
                   SET actividad = %s,
                       precision = %s
                 WHERE id = %s
            """, (sl_pred, sl_conf, req.id))

    return {
        "id": req.id,
        "pred_label": pred_label,
        "confianza": confianza,
        "actividad": sl_pred,
        "precision": sl_conf,
        "ask_label": ask,
        "ask_reason": ask_reason,
        "ask_id": ask_id,
        "sl_shadow": {"algo": SL_ALGO, "updates": SL_UPDATES, "promoted": SL_PROMOTED},
        "classes": list(map(str, CLASSES)),
    }

"""**Endpoint de prediccion pendiente**"""

@app.post("/predict_pending")
def predict_pending(req: PredictPendingReq):
    """
    Procesa ventanas donde pred_label es NULL.
    Puedes filtrar por id_usuario y/o session_id para un barrido específico.
    """
    done = 0

    # Construimos WHERE dinámico
    where = ["pred_label IS NULL"]
    params: list[Any] = []
    if req.id_usuario is not None:
        where.append("id_usuario = %s")
        params.append(req.id_usuario)
    if req.session_id is not None:
        where.append("session_id = %s")
        params.append(req.session_id)
    where_sql = " AND ".join(where)

    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Tomamos un lote estable y lo bloqueamos para evitar colisiones
        sql_sel = f"""
            SELECT *
              FROM windows
             WHERE {where_sql}
             ORDER BY id ASC
             LIMIT %s
             FOR UPDATE SKIP LOCKED
        """
        cur.execute(sql_sel, (*params, req.limit))
        rows = cur.fetchall()

        for row in rows:
            win_id = int(row["id"])
            # si no hay features JSON, _df_from_window_row usará columnas sueltas
            try:
                pred, conf = _svm_predict_row(row)
                _update_window_preds(cur, win_id, pred, conf)
                done += 1
            except Exception as e:
                # si una fila rara rompe, saltamos y seguimos con las demás
                # (opcional: loggear e)
                continue

        conn.commit()

    return {"processed": done}

"""**Endpoint para registrar que el usuario respondió una etiqueta**"""

@app.post("/label")
def post_label(req: LabelReq):
    st = req.start_ts.astimezone(timezone.utc)
    et = req.end_ts.astimezone(timezone.utc)
    if et <= st:
        raise HTTPException(400, "end_ts debe ser > start_ts")

    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # 1) Cerrar/crear intervalo (si hay pendiente, actualízalo; si no, inserta)
        cur.execute("""
            SELECT id
              FROM intervalos_label
             WHERE id_usuario = %s
               AND session_id  = %s
               AND label IS NULL
             ORDER BY created_at DESC
             LIMIT 1
             FOR UPDATE
        """, (req.id_usuario, req.session_id))
        pend = cur.fetchone()

        if pend:
            cur.execute("""
                UPDATE intervalos_label
                   SET label=%s, reason=%s, start_ts=%s, end_ts=%s, created_at=NOW()
                 WHERE id=%s
                RETURNING id
            """, (req.label, req.reason, st, et, pend["id"]))
            interval_id = cur.fetchone()["id"]
        else:
            cur.execute("""
                INSERT INTO intervalos_label
                    (start_ts, end_ts, label, reason, created_at, id_usuario, session_id)
                VALUES (%s, %s, %s, %s, NOW(), %s, %s)
                RETURNING id
            """, (st, et, req.label, req.reason, req.id_usuario, req.session_id))
            interval_id = cur.fetchone()["id"]

    # ENTRENAMIENTO ONLINE AL RECIBIR UNA ETIQUETA
        # 2.b) ENTRENAR SL con todas las ventanas cubiertas por [st, et]
        if SL_ENABLED and SL_LEARNER is not None:
            cur.execute("""
                SELECT id, features, *
                  FROM windows
                 WHERE id_usuario = %s
                   AND session_id  = %s
                   AND start_time < %s
                   AND end_time   > %s
                   AND COALESCE(sl_trained, FALSE) = FALSE
            """, (req.id_usuario, req.session_id, et, st))
            ws = cur.fetchall()

            global SL_UPDATES, SL_METRIC
            for wrow in ws:
                x = _row_to_x(wrow)
                y = req.label  # usa la etiqueta que envió el usuario
                # (opcional) evaluar antes de aprender (prequential)
                try:
                    y_hat = SL_LEARNER.predict_one(x)
                    if y_hat is not None:
                        SL_METRIC.update(y_true=y, y_pred=y_hat)
                except Exception:
                    pass

                SL_LEARNER.learn_one(x, y)
                SL_UPDATES += 1
                # marca para no re-entrenar esta ventana
                cur.execute("UPDATE windows SET sl_trained = TRUE WHERE id = %s", (wrow["id"],))

            # snapshot periódico
            if SL_UPDATES and SL_UPDATES % SL_SNAPSHOT_EVERY == 0:
                _sl_snapshot(conn, promoted=False)

        # 2) Commit en la misma transacción
        conn.commit()

    policy.mark_labeled(req.id_usuario, req.session_id, et.timestamp(), req.label)
    return {"ok": True, "interval_id": interval_id}

@app.post("/policy/asked")
def policy_mark_asked(req: MarkReq):
    policy.mark_asked(req.id_usuario, req.session_id, req.when.timestamp() if req.when else None)
    return {"ok": True}

@app.post("/policy/labeled")
def policy_mark_labeled(req: MarkReq):
    policy.mark_labeled(req.id_usuario, req.session_id, req.when.timestamp() if req.when else None)
    return {"ok": True}

"""**STREAM LEARNING**

Cargar o crear el learner
"""

@app.on_event("startup")
def _startup():
    global SL_LEARNER, SL_METRIC, SL_UPDATES
    if not SL_ENABLED:
        return
    # Crear learner (HT online)
    SL_LEARNER = _sl_make_learner()
    SL_METRIC = metrics.Accuracy()
    SL_UPDATES = 0

    # Intentar cargar snapshot más reciente
    try:
        with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS sl_models (
                  id           bigserial PRIMARY KEY,
                  created_at   timestamptz NOT NULL DEFAULT now(),
                  algo         text NOT NULL,
                  promoted     boolean NOT NULL DEFAULT false,
                  n_updates    integer NOT NULL,
                  metric       jsonb NOT NULL,
                  model_bytes  bytea NOT NULL
                )
            """)
            cur.execute("""
                SELECT algo, n_updates, metric, model_bytes
                  FROM sl_models
                 ORDER BY id DESC
                 LIMIT 1
            """)
            snap = cur.fetchone()
            if snap:
                model_bytes = snap["model_bytes"]
                SL_LEARNER = joblib.load(BytesIO(model_bytes))
                SL_UPDATES = int(snap["n_updates"])
                # métrica es informativa; Accuracy se resetea en tiempo real
    except Exception as e:
        # si no hay snapshot, seguimos con el árbol vacío
        pass

"""**Configuración de SL**"""

SL_ENABLED: bool = os.getenv("SL_ENABLED", "1") == "1"
SL_ALGO: str = os.getenv("SL_ALGO", "HT")  # por ahora solo HT
SL_MIN_SHADOW_UPDATES: int = int(os.getenv("SL_MIN_SHADOW_UPDATES", "5"))
SL_SNAPSHOT_EVERY: int = int(os.getenv("SL_SNAPSHOT_EVERY", "10"))

SL_LEARNER = None           # modelo online (HT)
SL_METRIC = metrics.Accuracy()
SL_UPDATES = 0              # # de learn_one() hechos
SL_PROMOTED = False         # si SL desplaza al SVM (solo para respuesta a la app)
SL_TRAIN_CHUNK = int(os.getenv("SL_TRAIN_CHUNK", "200"))

def _sl_make_learner():
    """Construye el learner de SL según SL_ALGO, con fallback seguro a HT."""
    from river import tree

    algo = (SL_ALGO or "HT").upper()

    if algo == "ARF":
        try:
            try:
                # River >= ~0.20
                from river.ensemble import ARFClassifier
            except Exception:
                # Intento con nombre antiguo (algunas builds)
                from river.ensemble import AdaptiveRandomForestClassifier as ARFClassifier
            return ARFClassifier(
                n_models=10,
                max_features="sqrt",
                lambda_value=6,
            )
        except Exception as e:
            # <<< NO reventar el startup >>>
            print("WARN: ARF no disponible en esta build de river → usando HT. Detalle:", repr(e))

    # Default / fallback: Hoeffding Tree
    return tree.HoeffdingTreeClassifier(
        grace_period=50,
        delta=1e-5,
        leaf_prediction="mc",
    )

"""**Función snapshot**"""

def _sl_snapshot(conn, promoted: bool = False):
    if not SL_ENABLED or SL_LEARNER is None:
        return
    buf = BytesIO(); joblib.dump(SL_LEARNER, buf); buf.seek(0)
    acc = float(SL_METRIC.get()) if SL_METRIC is not None else 0.0
    metric_json = {"accuracy": acc}
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO sl_models (algo, promoted, n_updates, metric, model_bytes)
            VALUES (%s, %s, %s, %s, %s)
        """, (SL_ALGO, promoted, SL_UPDATES, json.dumps(metric_json), psycopg2.Binary(buf.read())))

"""**Helpers para features**"""

def _row_to_x(row: Dict[str, Any]) -> Dict[str, float]:
    """Convierte fila windows → dict(feature -> valor) respetando SCHEMA."""
    if row.get("features"):
        feats: Dict[str, Any] = row["features"]
        return {f: float(feats.get(f, 0.0)) for f in FEATURES}
    return {f: float(row.get(f, 0.0)) for f in FEATURES}

"""**Inferir con SL**"""

def _sl_predict_row(row: dict):
    if SL_LEARNER is None:
        return None, None
    x = _row_to_x(row)
    proba = SL_LEARNER.predict_proba_one(x)  # dict {clase: prob}
    if not proba:
        return None, None
    cls = max(proba, key=proba.get)
    conf = float(proba[cls])
    return str(cls), conf

"""**Entrenar SL con etiquetas del usuario**"""

def _sl_train_on_row(row: dict, label: str):
    """
    Prequential: primero evalúa, luego entrena.
    Actualiza SL_METRIC. Marca sl_trained=true en windows.
    """
    global SL_LEARNER, SL_METRIC
    x = _row_to_x(row)
    y_true = str(label)
    y_hat = SL_LEARNER.predict_one(x)
    if y_hat is not None:
        SL_METRIC.update(y_true=y, y_pred=y_hat)
    SL_LEARNER.learn_one(x, y_true)
    # contador interno (para decidir cuándo guardar)
    n_updates = getattr(SL_LEARNER, "_n_updates", 0) + 1
    setattr(SL_LEARNER, "_n_updates", n_updates)
    return n_updates

"""**Endpoint para entrenar**"""

@app.post("/sl_train_pending")
def sl_train_pending(req: PredictPendingReq):
    """
    Entrena en batch con ventanas etiquetadas aún no usadas por SL.
    Respeta SL_TRAIN_CHUNK para evitar bloqueos largos.
    """
    if not SL_ENABLED or SL_LEARNER is None:
        return {"trained": 0, "updates": SL_UPDATES, "snapshot": False}

    trained = 0
    snap = False

    with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
        # Selecciona SOLO ventanas etiquetadas que aún no han sido usadas por SL
        # (y bloquea filas para evitar condiciones de carrera)
        cur.execute("""
            SELECT id, features, etiqueta, id_usuario, session_id, start_time, end_time
              FROM windows
             WHERE etiqueta IS NOT NULL
               AND COALESCE(sl_trained, FALSE) = FALSE
             ORDER BY id ASC
             LIMIT %s
             FOR UPDATE SKIP LOCKED
        """, (SL_TRAIN_CHUNK,))

        rows = cur.fetchall()
        if not rows:
            return {"trained": 0, "updates": SL_UPDATES, "snapshot": False}

        global SL_UPDATES
        for r in rows:
            x = _row_to_x(r)
            y = r["etiqueta"]

            # (opcional) evaluar antes de aprender para actualizar métrica
            try:
                y_hat = SL_LEARNER.predict_one(x)
                if y_hat is not None:
                    # ¡No reasignar!
                    SL_METRIC.update(y_true=y, y_pred=y_hat)
            except Exception:
                pass

            # Aprender
            SL_LEARNER.learn_one(x, y)
            SL_UPDATES += 1
            trained += 1

            # Marcar ventana como usada por SL
            cur.execute("UPDATE windows SET sl_trained = TRUE WHERE id = %s", (r["id"],))

        # Snapshot periódico
        if trained and (SL_UPDATES % SL_SNAPSHOT_EVERY == 0):
            _sl_snapshot(conn, promoted=False)
            snap = True

    return {"trained": trained, "updates": SL_UPDATES, "snapshot": snap}

"""**Endpoint de estado y promoción**"""

@app.get("/sl_status")
def sl_status():
    return {
        "algo": SL_ALGO,
        "promoted": SL_PROMOTED,
        "metric": {"accuracy": SL_METRIC.get()},
        "n_updates": SL_UPDATES
    }

@app.post("/sl_promote")
def sl_promote():
    global SL_PROMOTED
    SL_PROMOTED = True
    with get_conn() as conn:
        _sl_snapshot(conn, promoted=True)  # <-- en vez de _sl_save
    return {"ok": True, "promoted": True}

@app.post("/sl_reset")
def sl_reset():
    global SL_LEARNER, SL_METRIC, SL_PROMOTED
    SL_LEARNER = _sl_make_learner()
    SL_METRIC = metrics.Accuracy()
    SL_PROMOTED = False
    with get_conn() as conn:
        _sl_snapshot(conn, promoted=False)  # <-- en vez de _sl_save
    return {"ok": True}